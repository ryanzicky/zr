### Java线程实现/创建方式
    1. 继承Thread类
        Thread 类本质上是实现了 Runnable 接口的一个实例，代表一个线程的实例。启动线程的唯一方
        法就是通过 Thread 类的 start()实例方法。start()方法是一个 native 方法，它将启动一个新线
        程，并执行 run()方法
        public class MyThread extends Thread {
            public void run() {
                System.out.println("MyThread.run());
            }
        }
        
        MyThread myThread1 = new MyThread();
        myThread1.start();
    
    2. 实现Runnable接口
        如果自己的类已经 extends 另一个类，就无法直接 extends Thread，此时，可以实现一个
        Runnable 接口。
        
        public class MyThread extends OtherClass implements Runnable { 
            public void run() { 
                System.out.println("MyThread.run()"); 
            } 
        }
        
        //启动 MyThread，需要首先实例化一个 Thread，并传入自己的 MyThread 实例：
        MyThread myThread = new MyThread(); 
        Thread thread = new Thread(myThread); 
        thread.start(); 
        //事实上，当传入一个 Runnable target 参数给 Thread 后，Thread 的 run()方法就会调用
        target.run()
                    
        public void run() { 
             if (target != null) { 
                 target.run(); 
             } 
        }
        
    3. ExecutorService、Callable<Class>、Future 有返回值线程
        有返回值的任务必须实现 Callable 接口，类似的，无返回值的任务必须 Runnable 接口。执行
        Callable 任务后，可以获取一个 Future 的对象，在该对象上调用 get 就可以获取到 Callable 任务
        返回的 Object 了，再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程
        了。
        
        //创建一个线程池
        ExecutorService pool = Executors.newFixedThreadPool(taskSize);
        // 创建多个有返回值的任务
        List<Future> list = new ArrayList<Future>(); 
        for (int i = 0; i < taskSize; i++) { 
            Callable c = new MyCallable(i + " "); 
            // 执行任务并获取 Future 对象
            Future f = pool.submit(c); 
            list.add(f); 
        } 
        // 关闭线程池
        pool.shutdown(); 
        // 获取所有并发任务的运行结果
        for (Future f : list) { 
            // 从 Future 对象上获取任务的返回值，并输出到控制台
            System.out.println("res：" + f.get().toString()); 
        } 
    
    4. 基于线程池的方式
        线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销
        毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池
            // 创建线程池
            ExecutorService threadPool = Executors.newFixedThreadPool(10);
            while(true) {
                threadPool.execute(new Runnable() { // 提交多个线程任务，并执行
                    @Override
                    public void run() {
                        System.out.println(Thread.currentThread().getName() + " is running ..");
                        try {
                            Thread.sleep(3000);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                });
            }
         }
     
    4种线程池：
         1. newCachedThreadPool
         创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行
         很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造
         的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并
         从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资
         源
         
         2. newFixedThreadPool
         创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大
         多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，
         则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何
         线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之
         前，池中的线程将一直存在。
         
         3. newScheduledThreadPool
         创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行
         
         3. newSingletonThreadPool
         Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程
         池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！
         
    线程生命周期状态：
        当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。
        在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞
        (Blocked)和死亡(Dead)5 种状态。尤其是当线程启动以后，它不可能一直"霸占"着 CPU 独自
        运行，所以 CPU 需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换
    
        1. 新建(NEW)：
            当程序使用 new 关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配
            内存，并初始化其成员变量的值
            
        2. 就绪状态(RUNNABLE):
            当线程对象调用了 start()方法之后，该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和
            程序计数器，等待调度运行。
            
        3. 运行状态(RUNNING)：
            如果处于就绪状态的线程获得了 CPU，开始执行 run()方法的线程执行体，则该线程处于运行状
            态。
            
        4. 阻塞状态(BLOCKED)：
            阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice，暂时停止运行。
            直到线程进入可运行(runnable)状态，才有机会再次获得 cpu timeslice 转到运行(running)状
            态。阻塞的情况分三种：
            
                1. 等待阻塞(o.wait -> 等待队列)：
                    运行(running)的线程执行 o.wait()方法，JVM 会把该线程放入等待队列(waitting queue)
                    中。
                    
                2. 同步阻塞(lock -> 锁池)：
                    运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线
                    程放入锁池(lock pool)中
                    
                3. 其他阻塞(sleep/join)：
                    运行(running)的线程执行 Thread.sleep(long ms)或 t.join()方法，或者发出了 I/O 请求时，
                    JVM 会把该线程置为阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O
                    处理完毕时，线程重新转入可运行(runnable)状态。
                    
         5. 线程死亡(DEAD)：
            线程会以下面三种方式结束，结束后就是死亡状态
            1. 正常结束：
                run()或call()方法执行完成，线程正常结束
                
            2. 异常结束：
                线程抛出一个未捕获的Exception或Error
            
            3. 调用stop：
                直接调用该线程的 stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。
                
    sleep 与 wait 区别
        1. 对于 sleep()方法，我们首先要知道该方法是属于 Thread 类中的。而 wait()方法，则是属于
           Object 类中的
           
        2. sleep()方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是他的监控状态依然
           保持者，当指定的时间到了又会自动恢复运行状态。
           
        3. 在调用 sleep()方法的过程中，线程不会释放对象锁。
        
        4. 而当调用 wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此
           对象调用 notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。
           
    start 与 run 区别：
        1. start（）方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，
           可以直接继续执行下面的代码
        2. 通过调用 Thread 类的 start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运
           行。
        3. 方法 run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运
           行 run 函数当中的代码。 Run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程。
           
    Java后台线程
        1. 定义：守护线程--也称“服务线程”，他是后台线程，它有一个特性，即为用户线程 提供 公
        共服务，在没有用户线程可服务时会自动离开。
        2. 优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。
        3. 设置：通过 setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程
        的方式是在 线程对象创建 之前 用线程对象的 setDaemon 方法。
        4. 在 Daemon 线程中产生的新线程也是 Daemon 的。
        5. 线程则是 JVM 级别的，以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的
        生命周期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程
        依旧是活跃的。
        6. example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,
        程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线
        程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统
        中的可回收资源。
        7. 生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周
        期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依
        赖于系统，与系统“同生共死”。当 JVM 中所有的线程都是守护线程的时候，JVM 就可以退
        出了；如果还有一个或以上的非守护线程则 JVM 不会退出。
        
### Java锁
    1. 乐观锁：
        乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为
        别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数
        据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），
        如果失败则要重复读-比较-写的操作。
        java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，比较当前值跟传入
        值是否一样，一样则更新，否则失败
        
    2. 悲观锁：
        悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人
        会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。
        java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，
        才会转换为悲观锁，如 RetreenLock。
        
    3. 自旋锁：
        自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁
        的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），
        等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗
        
        自旋锁的优缺点：
            自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来
            说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会
            导致线程发生两次上下文切换！
            
            但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合
            使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量
            线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，
            其它需要 cup 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；
            
            
        自旋锁时间阈值（1.6 引入了适应性自旋锁）：
            自旋锁的目的是为了占着 CPU 的资源不释放，等到获取到锁立即进行处理。但是如何去选择
            自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而
            会影响整体系统的性能。因此自旋的周期选的额外重要！
            
    Synchronized 同步锁：
        synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁，同时属于可重
        入锁
        
        Synchronized 作用范围：
            1. 作用于方法时，锁住的是对象的实例(this)；
            2. 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen
            （jdk1.8 则是 metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，
            会锁所有调用该方法的线程；
            3. synchronized 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。它有多个队列，
            当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。
        
    ReentrantLock：
        ReentantLock 继承接口 Lock 并实现了接口中定义的方法，他是一种可重入锁，除了能完
        成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等
        避免多线程死锁的方法。
         
        Lock 接口的主要方法：
            
            
    ReentrantLock 与 synchronized：
        1. ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作，与 synchronized 会 被 JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁。为了避免程序出
        现异常而无法正常解锁的情况，使用 ReentrantLock 必须在 finally 控制块中进行解锁操
        作。
        2. ReentrantLock 相比 synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要
        使用 ReentrantLock
        
    Semaphore 信号量：
        Semaphore 是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信
        号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore 可以用来
        构建一些对象池，资源池之类的，比如数据库连接池
        
        实现互斥锁（计数器为 1）：
            我们也可以创建计数为 1 的 Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，
            表示两种互斥状态
            
    Semaphore与ReenTrantLock：
        
    AtomicInteger：
    AtomicBoolean：
    AtomicLong：
    AtomicLong：
    AtomicReference：
    
    我们知道，在多线程程序中，诸如++i 或 i++等运算不具有原子性，是不安全的线程操作之一。
    通常我们会使用 synchronized 将该操作变成一个原子操作，但 JVM 为此类操作特意提供了一些
    同步类，使得使用更方便，且使程序运行效率变得更高。通过相关资料显示，通常AtomicInteger
    的性能是 ReentantLock 的好几倍
    
    可重入锁（递归锁）：
    公平锁与非公平锁：
        公平锁（Fair）：
            加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得
        非公平锁（Nonfair）：
            加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待
            
            1. 非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列
            2. Java 中的 synchronized 是非公平锁，ReentrantLock 默认的 lock()方法采用的是非公平锁。
            
    ReadWriteLock 读写锁：
        读锁：
            如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁
        写锁：
            如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上
            读锁，写的时候上写锁！
            
    
    共享锁和独占锁：
        java 并发包提供的加锁模式分为独占锁和共享锁
        
        独占锁：
            独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。
            独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线
            程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性
            
        共享锁：
            共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种
            乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。
            
            1. AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等
            待线程的锁获取模式。
            2. java 的并发包中提供了 ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，
            或者被一个 写操作访问，但两者不能同时进行
            
    重量级锁（Mutex Lock）：
        Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又
        是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用
        户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么
        Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为
        “重量级锁”。JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。
        JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和
        “偏向锁”
        
    轻量级锁：
        锁的状态总共有四种：
            无锁状态
            偏向锁
            轻量级锁
            重量级锁
            
        锁升级：
             随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，
             也就是说只能从低到高升级，不会出现锁的降级）。
             
             “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，
             轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量
             级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场
             景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀
             为重量级锁。
             
        偏向锁：
        分段锁：
            ConcurrentHashMap分段锁
            
        锁优化：
            1. 减少锁持有时间：
                只用在有线程安全要求的程序上加锁
            2. 减小锁粒度
                将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。
                降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是
                ConcurrentHashMap
                
        锁分离：
            最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互
            斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发 Java 五] 
            JDK 并发包 1。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如
            LinkedBlockingQueue 从头部取出，从尾部放数据
            
        锁粗化：
            通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完
            公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步
            和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化
         
         锁消除：
            锁消除是在编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这
            些对象的锁操作，多数是因为程序员编码不规范引起
            
### 线程基本方法
    线程相关的基本方法有 wait，notify，notifyAll，sleep，join，yield 等。
    1. 线程等待（wait）
        调用该方法的线程进入 WAITING 状态，只有等待另外线程的通知或被中断才会返回，需要注意的
        是调用 wait()方法后，会释放对象的锁。因此，wait 方法一般用在同步方法或同步代码块中
    2. 线程睡眠（sleep）
        sleep 导致当前线程休眠，与 wait 方法不同的是 sleep 不会释放当前占有的锁,sleep(long)会导致
        线程进入 TIMED-WATING 状态，而 wait()方法会导致当前线程进入 WATING 状态
    3. 线程让步（yield）
        yield 会使当前线程让出 CPU 执行时间片，与其他线程一起重新竞争 CPU 时间片。一般情况下，
        优先级高的线程有更大的可能性成功竞争得到 CPU 时间片，但这又不是绝对的，有的操作系统对
        线程优先级并不敏感。
    4. 线程中断（interrupt）
        中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这
        个线程本身并不会因此而改变状态(如阻塞，终止等)
        1. 调用 interrupt()方法并不会中断一个正在运行的线程。也就是说处于 Running 状态的线
           程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已。
        2. 若调用 sleep()而使线程处于 TIMED-WATING 状态，这时调用 interrupt()方法，会抛出
           InterruptedException,从而使线程提前结束 TIMED-WATING 状态。
        3. 许多声明抛出 InterruptedException 的方法(如 Thread.sleep(long mills 方法))，抛出异
           常前，都会清除中断标识位，所以抛出异常后，调用 isInterrupted()方法将会返回 false
        4. 中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止
           一个线程 thread 的时候，可以调用 thread.interrupt()方法，在线程的 run 方法内部可以
           根据 thread.isInterrupted()的值来优雅的终止线程
    
    5. Join 等待其他线程终止
        join() 方法，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞
        状态，回到另一个线程结束，当前线程再由阻塞状态变为就绪状态，等待 cpu 的宠幸
           
    6. 为什么要用 join()方法？
        很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要
        在子线程结束后再结束，这时候就要用到 join() 方法。
        
    7. 线程唤醒（notify）
        Object 类中的 notify() 方法，唤醒在此对象监视器上等待的单个线程，如果所有线程都在此对象
        上等待，则会选择唤醒其中一个线程，选择是任意的，并在对实现做出决定时发生，线程通过调
        用其中一个 wait() 方法，在对象的监视器上等待，直到当前的线程放弃此对象上的锁定，才能继
        续执行被唤醒的线程，被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞
        争。类似的方法还有 notifyAll() ，唤醒再次监视器上等待的所有线程。
    
    8. 其他方法：
        1. sleep()：强迫一个线程睡眠Ｎ毫秒。
        2. isAlive()： 判断一个线程是否存活。
        3. join()： 等待线程终止。
        4. activeCount()： 程序中活跃的线程数。
        5. enumerate()： 枚举程序中的线程。
        6. currentThread()： 得到当前线程。
        7. isDaemon()： 一个线程是否为守护线程。
        8. setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线
        程依赖于主线程结束而结束) 
        9. setName()： 为线程设置一个名称。
        10. wait()： 强迫一个线程等待。
        11. notify()： 通知一个线程继续运行。
        12. setPriority()： 设置一个线程的优先级。
        13. getPriority():：获得一个线程的优先级。
     
    线程上下文切换：
        巧妙地利用了时间片轮转的方式, CPU 给每个任务都服务一定的时间，然后把当前任务的状态保存
        下来，在加载下一任务的状态后，继续服务下一任务，任务的状态保存及再加载, 这段过程就叫做
        上下文切换。时间片轮转的方式使多个任务在同一颗 CPU 上执行变成了可能
        
    线程池的组成：
        1. 线程池管理器：用于创建并管理线程池
        2. 工作线程：线程池中的线程
        3. 任务接口：每个任务必须实现的接口，用于工作线程调度运行
        4. 任务队列：用于存放待处理的任务，提供一种缓冲机制
        
        1. corePoolSize：指定了线程池中的线程数量
        2. maximumPoolSize：指定了线程池中的最大线程数量
        3. keepAliveTime：当前线程池数量超过corePoolSize时，多余的空闲线程的存活时间
            即多次时间内会被销毁
        4. unit：keepAliveTime的单位
        5. workQueue：任务队列，被提交但尚未被执行的任务
        6. threadFactory：线程工厂，用于创建线程，一般用默认的即可
        7. handler：拒绝策略，当任务太多来不及处理，如何拒绝任务
        
    拒绝策略：
        1. AbortPolicy ： 直接抛出异常，阻止系统正常运行。
        2. CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的
        任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
        3. 3. DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再
           次提交当前任务。
        4. DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢
        失，这是最好的一种方案。
        
    Java线程池工作线程：
        1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面
        有任务，线程池也不会马上执行它们。
        2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：
            a) 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；
            b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；
            c) 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要
            创建非核心线程立刻运行这个任务；
            d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池
            会抛出异常 RejectExecutionException。
        3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。
        4. 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运
        行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它
        最终会收缩到 corePoolSize 的大小。
    
    Java阻塞队列原理
        阻塞队列，关键字是阻塞，先理解阻塞的含义，在阻塞队列中，线程阻塞有这样两种情况：
            1. 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放
            入队列。
            2. 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有
            空的位置，线程被自动唤醒。
            
            插入：
                抛出异常：add(e)
                特殊值：offer(e)
                阻塞：put(e)
                超时：offer(e, time, unit)
            
            移除：
                抛出异常：remove()
                特殊值：poll()
                阻塞：take()
                超时：poll(time, unit)
             
            检查：
                抛出异常：element()
                特殊值：peek()
                阻塞：不可用
                超时：不可用
    
    Java中的阻塞队列：
        1. ArrayBlockingQueue：由数组结构组成的有界阻塞队列
            此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下
            不保证访问者公平的访问队列
            ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000, true);
            
        2. LinkedBlockingQueue：由链表结构组成的有界阻塞队列
            两个独立锁提高并发
            基于链表的阻塞队列，同 ArrayListBlockingQueue 类似，此队列按照先进先出（FIFO）的原则对
            元素进行排序。而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生产者
            端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费
            者可以并行地操作队列中的数据，以此来提高整个队列的并发性能
            
        3. PriorityBlockingQueue：支持优先级排序的无界阻塞队列
            compareTo 排序实现优先
            是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现
            compareTo()方法来指定元素进行排序规则，或者初始化 PriorityBlockingQueue 时，指定构造
            参数 Comparator 来对元素进行排序。需要注意的是不能保证同优先级元素的顺序
            
        4. DelayQueue：使用优先级队列实现的无界阻塞队列
            缓存失效，定时任务
            是一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。队列中的元素必须实
            现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才
            能从队列中提取元素。我们可以将 DelayQueue 运用在以下应用场景：
                1. 缓存系统的设计：可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询
                DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期到了。
                2. 定时任务调度：使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从
                DelayQueue 中获取到任务就开始执行，从比如 TimerQueue 就是使用 DelayQueue 实现的。
                
        5. SynchronousQueue：不存储元素的阻塞队列
            不存储数据，可用于传递数据
            是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。
            
        6. LinkedTransferQueue：由链表结构组成的无界阻塞队列
            是 一 个 由 链 表 结 构 组 成 的 无 界 阻 塞 TransferQueue 队 列 。 相 对 于 其 他 阻 塞 队 列 ，
            LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。
                1. transfer 方法：如果当前有消费者正在等待接收元素（消费者使用 take()方法或带时间限制的
                poll()方法时），transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如
                果没有消费者在等待接收元素，transfer 方法会将元素存放在队列的 tail 节点，并等到该元素
                被消费者消费了才返回。
                2. tryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费
                者等待接收元素，则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否
                接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。
                对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传
                入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时
                还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。
            
        7. LinkedBlockingDeque：由链表结构组成的双向阻塞队列
            
    
### CyclicBarrier、CountDownLatch、Semaphore 的用法
    1. CountDownlatch(线程计数器)
        CountDownLatch 类位于 java.util.concurrent 包下，利用它可以实现类似计数器的功能。比如有
        一个任务 A，它要等待其他 4 个任务执行完毕之后才能执行，此时就可以利用 CountDownLatch
        来实现这种功能了
        
    2. CyclicBarrier(回环栅栏-等待至barrier状态在全部同时执行)
        字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环
        是因为当所有等待线程都被释放以后，CyclicBarrier 可以被重用。我们暂且把这个状态就叫做
        barrier，当调用 await()方法之后，线程就处于 barrier 了。
        
        CyclicBarrier 中最重要的方法就是 await 方法，它有 2 个重载版本:
            1. public int await()：用来挂起当前线程，直至所有线程都到达 barrier 状态再同时执行后续任
            务；
            2. public int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有
            线程没有到达 barrier 状态就直接让到达 barrier 的线程执行后续任务。
            
    3. Semaphore(信号量 - 控制同时访问的线程个数)
        Semaphore 可以控制同时访问的线程个数，通过
        acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。
        Semaphore 类中比较重要的几个方法：
            1. public void acquire(): 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许
            可。
            2. public void acquire(int permits):获取 permits 个许可
            3. public void release() { } :释放许可。注意，在释放许可之前，必须先获获得许可。
            4. public void release(int permits) { }:释放 permits 个许可
            
    上面 4 个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法
    
    
    - CountDownLatch 和 CyclicBarrier 都能够实现线程之间的等待，只不过它们侧重点不
    同；CountDownLatch 一般用于某个线程 A 等待若干个其他线程执行完任务之后，它才
    执行；而 CyclicBarrier 一般用于一组线程互相等待至某个状态，然后这一组线程再同时
    执行；另外，CountDownLatch 是不能够重用的，而 CyclicBarrier 是可以重用的。
    
    - Semaphore 其实和锁有点类似，它一般用于控制对某组资源的访问权限。
    
### volatile关键字(变量可见性，禁止重排序)
    Java 语言提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作通知到其他
    线程。volatile 变量具备两种特性，volatile 变量不会被缓存在寄存器或者对其他处理器不可见的
    地方，因此在读取 volatile 类型的变量时总会返回最新写入的值。
    
    变量可见性：
        其一是保证该变量对所有线程可见，这里的可见性指的是当一个线程修改了变量的值，那么新的
        值对于其他线程是可以立即获取的
        
        MESI一致性协议
        M：修改
        E：独占
        S：共享
        I：失效
    
    禁止重排序：
        volatile 禁止了指令重排。
        Lock指令
        内存屏障
        loadload
        loadstore
        storestore
        storeload
        
    比 sychronized 更轻量级的同步锁
        在访问 volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此 volatile 变量是一
        种比 sychronized 关键字更轻量级的同步机制。volatile 适合这种场景：一个变量被多个线程共
        享，线程直接给这个变量赋值。
        
        当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到 CPU 缓存中。如果计算机有
        多个 CPU，每个线程可能在不同的 CPU 上被处理，这意味着每个线程可以拷贝到不同的 CPU 
        cache 中。而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache 
        这一步
        
    适用场景:
        值得说明的是对 volatile 变量的单次读/写操作可以保证原子性的，如 long 和 double 类型变量，
        但是并不能保证 i++这种操作的原子性，因为本质上 i++是读、写两次操作。在某些场景下可以
        代替 Synchronized。但是,volatile 的不能完全取代 Synchronized 的位置，只有在一些特殊的场
        景下，才能适用 volatile。总的来说，必须同时满足下面两个条件才能保证在并发环境的线程安
        全
        
        （1）对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean 
        flag = true）。
        （2）该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不
        能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。
        
### 如何在两个线程之间共享数据
    Java 里面进行多线程通信的主要方式就是共享内存的方式，共享内存主要的关注点有两个：可见
    性和有序性原子性。Java 内存模型（JMM）解决了可见性和有序性的问题，而锁解决了原子性的
    问题，理想情况下我们希望做到“同步”和“互斥”。有以下常规实现方法:
        1. 将数据抽象成一个类，并将数据的操作作为这个类的方法
        2. Runnable 对象作为一个类的内部类
        3. ThreadLocal(线程本地存储)
            ThreadLocalMap(线程的一个属性)
            1. 每个线程中都有一个自己的 ThreadLocalMap 类对象，可以将线程自己的对象保持到其中，
            各管各的，线程可以正确的访问到自己的对象
            2. 将一个共用的 ThreadLocal 静态实例作为 key，将不同对象的引用保存到不同线程的
            ThreadLocalMap 中，然后在线程执行的各处通过这个静态 ThreadLocal 实例的 get()方法取
            得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦
            3. ThreadLocalMap 其实就是线程里面的一个属性，它在 Thread 类中定义
                ThreadLocal.ThreadLocalMap threadLocals = null;
                最常见的 ThreadLocal 使用场景为 用来解决 数据库连接、Session 管理等。
          
### Synchronized和ReenTrantLock的区别
    共同点：
        1. 都是用来协调多线程对共享对象、变量的访问
        2. 都是可重入锁，同一线程可以多次获得同一个锁
        3. 都保证了可见性和互斥性
    
    不同点：
        1. ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁
        2. ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的
        不可用性提供了更高的灵活性
        3. ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的
        4. ReentrantLock 可以实现公平锁
        5. ReentrantLock 通过 Condition 可以绑定多个条件
        6. 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻
        塞，采用的是乐观并发策略
        7. Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言
        实现
        8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
        而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，
        因此使用 Lock 时需要在 finally 块中释放锁。
        9. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，
        等待的线程会一直等待下去，不能够响应中断
        10. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
        11. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等
        
### ConcurrentHashMap 并发
    1. 减小锁粒度
        减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减
        小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是 ConcurrentHashMap(高
        性能的 HashMap)类的实现。对于 HashMap 而言，最重要的两个方法是 get 与 set 方法，如果我
        们对整个 HashMap 加锁，可以得到线程安全的对象，但是加锁粒度太大。Segment 的大小也被
        称为 ConcurrentHashMap 的并发度。
    
    2. ConcurrentHashMap 分段锁
        ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下
        一个 ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度。
        如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首
        先根据 hashcode 得到该表项应该存放在哪个段中，然后对该段加锁，并完成 put 操作。在多线程
        环境中，如果多个线程同时进行 put操作，只要被加入的表项不存放在同一个段中，则线程间可以
        做到真正的并行。
        
    ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成
        ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。Segment 是一种可
        重入锁 ReentrantLock，在 ConcurrentHashMap 里扮演锁的角色，HashEntry 则用于存储键值
        对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的结构和 HashMap
        类似，是一种数组和链表结构， 一个 Segment 里包含一个 HashEntry 数组，每个 HashEntry 是
        一个链表结构的元素， 每个 Segment 守护一个 HashEntry 数组里的元素,当对 HashEntry 数组的
        数据进行修改时，必须首先获得它对应的 Segment 锁
        
### Java中用到的线程调度
    1. 抢占式调度
        抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种
        运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至
        某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。
    
    2. 协同式调度
        协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行，这种模式就像接力赛一样，
        一个人跑完自己的路程就把接力棒交接给下一个人，下个人继续往下跑。线程的执行时间由线程
        本身控制，线程切换可以预知，不存在多线程同步问题，但它有一个致命弱点：如果一个线程编
        写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃
    
### 线程让出 cpu 的情况
    1. 当前运行线程主动放弃 CPU，JVM 暂时放弃 CPU 操作（基于时间片轮转调度的 JVM 操作系
    统不会让线程永久放弃 CPU，或者说放弃本次时间片的执行权），例如调用 yield()方法。
    2. 当前运行线程因为某些原因进入阻塞状态，例如阻塞在 I/O 上
    3. 当前运行线程结束，即运行完 run()方法里面的任务。
    
### 进程调度算法
    1. 优先调度算法
        1. 先来先服务调度算法（FCFS）
        2. 短作业(进程)优先调度算法
        
    2. 高优先权优先调度算法
        1. 非抢占式优先权算法
        2. 抢占式优先权调度算法
    
    3．高响应比优先调度算法
    
    4. 基于时间片的轮转调度算法
        1. 时间片轮转算法


### 什么是CAS(比较并交换-乐观锁机制-锁自旋)
     1. 概念及特性
        CAS(Compare And Swap/Set)比较并交换，CAS算法的过程是这样的：
            它包含3个参数
            CAS(V,E,N):
                V表示要更新的变量(内存值)
                E表示预期值(旧的)
                N表示新值
                当且仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明
                已经有其他线程做了更新，则当前线程什么都不做，最后，CAS返回当前V的真实值
                
            CAS 操作是抱着乐观的态度进行的(乐观锁)，它总是认为自己可以成功完成操作。当多个线程同时
            使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂
            起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，
            CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理
            
### 原子包 java.util.concurrent.atomic（锁自旋）

### 什么是AQS(抽象的队列同步器)
    AbstractQueuedSynchronizer 类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源
    的同步器框架，许多同步类实现都依赖于它，如常用的：
        ReenTrantLock/Semaphore/CountDownlatch
        
        CLH队列(FIFO)
        
        它维护了一个volatile int state(代表共享资源)和一个FIFO线程等待队列(多线程争用资源被阻塞时会进入此队列)
        这里volatile是核心关键词。
        state的访问方式有三种：
            getState()
            setState()
            compareAndSetState()
            
    AQS定义两种资源共享方式
        Exclusive独占资源-ReenTrantLock
            Exclusive(独占，只有一个线程能执行，如ReenTrantLock)
        Share 共享资源 - Semaphore/CountDownLatch
            Share(共享，多个线程同时执行，如 Semaphore/CountDownLatch)
    
    AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现
    通过state的 get/set/CAS 
    自定义同步器实现主要实现以下几种方法：
        1. isHeldExclusively()：该线程是否正在独占资源
        2. tryAcquire(int)：独占方式，尝试获取资源，成功返回true，失败返回false
        3. tryRelease(int)：独占方式，尝试释放资源，成功返回true，失败返回false
        4. tryAcquireShared(int)：共享方式，尝试获取资源，负数表示失败，0表示成功，但没有剩余可用资源
            整数表示成功，且有剩余资源
        5. tryRelaaseShared(int)：共享方式，尝试释放资源，如果释放后允许唤醒后续等待节点返回true
            否则返回false
            
            
    同步器的实现是ABS核心(state 资源状态计数)
    同步器的实现是ABS核心，以ReenTrantLock为例，state初始化为0，表示未锁定状态。
    A线程lock()时，会调用teyAcquire()独占该锁并将state + 1，此后，其他线程 再tryAcquire()时
    就会失败，知道A线程unlock()到state = 0(即释放锁)为止，其他线程才有机会获取该锁，当然，释放
    锁之前，A线程自己是可以重复获取此锁的(state会累加)，这样是可重入锁的概念，但要注意，获取多少次
    就要释放多少次，这样才能保证state是能回到零态的
    
    
        
    