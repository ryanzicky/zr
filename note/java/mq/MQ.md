### Kafka，RabbitMQ的区别
    Kafka采取拉取(pull)方式消费消息，吞吐量高，适用于海量数据收集与传递场景，
    例如日志采集和集中分析
    
    RabbitMQ在吞吐量方面略有逊色，但支持更多的消息队列功能
    
    
    性能：
        消息中间件的性能主要衡量吞吐量，Kafka的吞吐量比RabbitMQ要高出1~2个数量级
        RabbitMQ的单机QPS在万级别，Kafka的单机QPS能够达到百万级别，
        Kafak如果开启幂等，事务等功能，性能也会有所降低
        
    数据可靠性：
        Kafka与RabbitMQ都具备多副本机制，数据可靠性高，RocketMQ支持异步实时刷盘
        同步刷盘，同步Relication，异步Replication
    
    服务可用性：
        Kafka采用集群部署，分区与多副本的设计，使得单节点宕机对服务无影响，
        且支持消息容量的线性提升
        RabbitMQ支持集群部署，集群节点数量有多种规格
        RocketMQ是分布式架构，可用性高
        
    功能：
        
        
### 异步消息模式
    1. 消息队列
        利用消息队列可以解耦生产者和消费者，多个生产者可以向同一个消息队列
        发送消息，但是一个消息在被一个消费者处理的时候，这个消息在队列上会被
        锁住或者被移除并且其他消费者无法处理该消息。也就是说一个具体的消息只能
        由一个消费者消费
        
        需要额外注意的是，如果消费者处理一个消息失败了，消息系统一般会把这个消息
        放回队列，这样其他消费者可以继续处理，消息队列除了提供解耦功能之外，它
        还能对生产者和消费者独立的伸缩，以及提供对错误处理的容错能力
        
    2. 发布/订阅
        发布订阅模式中，单个消息可以被多个订阅者并发的获取和处理
        
        例如，一个系统中产生的时间可以通过这种模式让发布者通知所有订阅者
        在许多队列中常常用主题(topic)这个术语指代发布/订阅模式。
        在RabbitMQ中，主题是发布/订阅模式的一种具体实现(更准确点说是交换器
        (Exchange)的一种)
        
        一般来说。订阅有两种类型：
            1. 临时(eohemeral)订阅，这种订阅只有在消费者启动并且运行的时候才存在，
            一旦消费者退出，相应的订阅以及尚未处理的消息就会丢失
            
            2. 持久(durable)订阅，这种订阅会一直存在，除非主动去删除，消费者
            退出后，消息系统会继续维护该订阅，并且后续消息可以被继续处理
            
            
     
###  RabbitMQ
    1. 队列
        RabbitMQ支持典型的开箱即用的消息队列，开发者可以定义一个命名队列，
        然后发布者可以向这个命名队列中发送消息，最后消费者可以通过这个命名
        队列获取待处理的消息
        
    2. 消息交换器
       RabbitMQ使用消息交换器来实现发布/订阅模式，发布者可以把消息发布到消息
       交换器上而不用知道这些消息都有哪些订阅者
       
       每一个订阅了交换器的消费者都会创建一个队列，然后消息交换器会把生产的消息
       放入队列以供消费者消费，消息交换器也可以基于各种路由规则为一些订阅者过滤消息
       
       需要注意的是RabbitMQ支持临时和持久两种订阅类型，消费者可以调用RabbitMQ的API
       来选择他们想要的订阅类型
       
### Apache Kafka
    Kafka不是消息中间件的一种实现，相反，它只是一种分布式流式系统
    
    不同于基于队列和交换器的RabbitMQ，Kafka的存储层是使用分布式事务日志来实现的
    Kafka也提供流式API用于实时的流处理以及连接器API用来更容易的和各种数据源集成
    
    1. 主题(Topic)：
        Kafka没有实现队列这中东西，相应的，Kafka按照类别存储记录集，并且把这种类别
        称为主题
        
        Kafka为每个主题维护一个消息分区日志，每个分区都是由有序的不可变的记录序列组成
        并且消息是连续的被追加在尾部
        
        当消息到达时，Kafka就会把他们追加到分区尾部，默认情况下，Kafka使用轮询分区
        器(partition)把消息一直的分配到多个分区上
        
        Kafka可以该表消息逻辑流的行为，例如，在一个多租户的应用中，我们可以根据每个消息
        中的租户ID创建消息流，IOT场景中，我们可以在常数级别下根据生产者的身份消息(identity)
        将其映射到一个具体的分区上，确保来自相同逻辑流上的消息映射到相同分区上，这就保证了
        消息能够按照顺序提供给消费者
        
        
        消费者通过维护分区的偏移(或者说索引)来顺序的读出消息，然后消费消息
        
        单个消费者可以消费多个不同的主题，并且消费者的数量可以伸缩到可获取的最大分区数量
        
        所以在创建主题的时候，我们要认真的考虑一下在创建的主题上预期的消息吞吐量，消费
        同一个主题的多个消费者构成的组成为消费者组，通过Kafka提供的API可以处理同一组
        消费者卒中多个消费者之间的分区平衡以及消费者当前分区偏移的存储
        
    2. Kafka实现的消息模式
        Kafka的实现很好地契合发布/订阅模式
        
        生产者可以向一个具体的主题发送消息，然后多个消费者可以消费相同的消息，
        每一个消费者组都可以独立的伸缩去处理相应的负载，由于消费者维护自己的分区偏移
        所以它们可以选择持久定于或者临时订阅，持久订阅在重启之后不会丢失偏移而临时
        订阅在重启之后会丢失偏移并且每次重启之后都会从分区中最新的记录开始读取
        
        但是这种实现方案不能完全等价的当作典型的消息队列模式来看待，当然，我们创建
        一个主题，这个主题和拥有一个消费者的消费者组进行关联，这样我们就模拟出了一个典型
        的消息队列，不过这回有许多缺点
        
        值得注意的是，Kafka是按照玉宪配置好的时间保留分区中的消息，而不是根据消费者是否
        消费了这些消息，这种保留机制可以让消费者自由的重读之前的消息，另外，开发者
        也可以利用Kafka的存储层来实现诸如时间溯源和日志审计功能
        
        
### RabbitMQ和Kafka的区别
    RabbitMQ是一个消息中间件
    Kafka一个是分布式流是系统
    
    Kafka最适用于数据的流式处理，但是RabbitMQ对流式中的消息就很难保证它们的顺序
    
    另一方面，RabbitMQ内置重试逻辑和死信(dead-letter)交换器，但是Kafka只是把这些实现
    逻辑交给用户来处理
    
    
    1. 消息顺序
        对于发送到队列或者交换器上的消息，RabbitMQ不保证它们的顺序，尽管消费者按照
        顺序来处理生产者发来的消息看上去很符合逻辑，但是这有很大误导性
        
        RabbitMQ文档中有关于消息顺序保证的说明：
            “发布到一个通道（channel）上的消息，用一个交换器和一个队列
            以及一个出口通道来传递，那么最终会按照它们发送的顺序接收到。” 
            
        换话句话说，只要我们是单个消费者，那么接收到的消息就是有序的。然而，
        一旦有多个消费者从同一个队列中读取消息，那么消息的处理顺序就没法保证了。
        
        由于消费者读取消息之后可能会把消息放回（或者重传）到队列中
        （例如，处理失败的情况），这样就会导致消息的顺序无法保证。
        
        一旦一个消息被重新放回队列，另一个消费者可以继续处理它，
        即使这个消费者已经处理到了放回消息之后的消息。因此，消费者组处理消息是无序的，如下表所示：
        
        当然，我们可以通过限制消费者的并发数等于1来保证RabbitMQ中的消息有序性。
        更准确点说，限制单个消费者中的线程数为1，因为任何的并行消息处理都会导致无序问题。
        不过，随着系统规模增长，单线程消费者模式会严重影响消息处理能力。所以，我们不要轻易的选择这种方案。
        
        另一方面，对于Kafka来说，它在消息处理方面提供了可靠的顺序保证。Kafka能够保证发送到相同主题分区的所有消息都能够按照顺序处理。
        在前面说过，默认情况下，Kafka会使用循环分区器（round-robin partitioner）把消息放到相应的分区上。不过，生产者可以给每个消息设置分区键（key）
        来创建数据逻辑流（比如来自同一个设备的消息，或者属于同一租户的消息）。
        所有来自相同流的消息都会被放到相同的分区中，这样消费者组就可以按照顺序处理它们。
        但是，我们也应该注意到，在同一个消费者组中，每个分区都是由一个消费者的一个线程来处理。结果就是我们没法伸缩（scale）单个分区的处理能力。
        不过，在Kafka中，我们可以伸缩一个主题中的分区数量，这样可以让每个分区分担更少的消息，然后增加更多的消费者来处理额外的分区。
        
    2. 消息路由
        RabbitMQ可以基于定义的订阅者路由规则路由消息给一个消息交换器上的订阅者。
        一个主题交换器可以通过一个叫做routing_key的特定头来路由消息。     
    
        或者，一个头部（headers）交换器可以基于任意的消息头来路由消息。
        这两种交换器都能够有效地让消费者设置他们感兴趣的消息类型，因此可以给解决方案架构师提供很好的灵活性。
        
        另一方面，Kafka在处理消息之前是不允许消费者过滤一个主题中的消息。
        一个订阅的消费者在没有异常情况下会接受一个分区中的所有消息。
    
        作为一个开发者，你可能使用Kafka流式作业（job），它会从主题中读取消息，然后过滤，
        最后再把过滤的消息推送到另一个消费者可以订阅的主题。但是，这需要更多的工作量和维护，并且还涉及到更多的移动操作。
        
        获胜者：
            在消息路由和过滤方面，RabbitMQ提供了更好的支持。
    
    3. 消息时序(timing)
        在测定发送到一个队列的消息时间方面，RabbitMQ提供了多种能力：
        1. 消息存活时间（TTL）
            发送到RabbitMQ的每条消息都可以关联一个TTL属性。发布者可以直接设置TTL或者根据队列的策略来设置。
            
            系统可以根据设置的TTL来限制消息的有效期。如果消费者在预期时间内没有处理该消息，
            那么这条消息会自动的从队列上被移除（并且会被移到死信交换器上，同时在这之后的消息都会这样处理）。
            
            TTL对于那些有时效性的命令特别有用，因为一段时间内没有处理的话，这些命令就没有什么意义了。
       
        2. 延迟/预定的消息
            RabbitMQ可以通过插件的方式来支持延迟或者预定的消息。当这个插件在消息交换器上启用的时候，
            生产者可以发送消息到RabbitMQ上，然后这个生产者可以延迟RabbitMQ路由这个消息到消费者队列的时间。
            
            Kafka没有提供这些功能。它在消息到达的时候就把它们写入分区中，这样消费者就可以立即获取到消息去处理。
            Kafka也没用为消息提供TTL的机制，不过我们可以在应用层实现。
            不过，我们必须要记住的一点是Kafka分区是一种追加模式的事务日志。所以，它是不能处理消息时间（或者分区中的位置）。
            
            毫无疑问，RabbitMQ是获胜者，因为这种实现天然的就限制Kafka。
            
    4. 消息留存(retention)
                当消费者成功消费消息之后，RabbitMQ就会把对应的消息从存储中删除。这种行为没法修改。
                它几乎是所有消息代理设计的必备部分。
                
                相反，Kafka会给每个主题配置超时时间，只要没有达到超时时间的消息都会保留下来。在消息留存方面，
                Kafka仅仅把它当做消息日志来看待，并不关心消费者的消费状态。
                
                消费者可以不限次数的消费每条消息，并且他们可以操作分区偏移来“及时”往返的处理这些消息。
                Kafka会周期的检查分区中消息的留存时间，一旦消息超过设定保留的时长，就会被删除。
                
                Kafka的性能不依赖于存储大小。所以，理论上，它存储消息几乎不会影响性能（只要你的节点有足够多的空间保存这些分区）。
                
                Kafka设计之初就是保存消息的，但是RabbitMQ并不是。所以这块没有可比性，Kafka是获胜者。
            
    5. 容错处理
                当处理消息，队列和事件时，开发者常常认为消息处理总是成功的。毕竟，生产者把每条消息放入队列或者主题后，
                即使消费者处理消息失败了，它仅仅需要做的就是重新尝试，直到成功为止。
                
                尽管表面上看这种方法是没错的，但是我们应该对这种处理方式多思考一下。首先我们应该承认，
                在某些场景下，消息处理会失败。所以，即使在解决方案部分需要人为干预的情况下，我们也要妥善地处理这些情况。   
                
                消息处理存在两种可能的故障：
                    1. 瞬时故障：
                        故障产生是由于临时问题导致，比如网络连接，CPU负载，或者服务崩溃。我们可以通过一遍又一遍的尝试来减轻这种故障。
                    
                    2. 持久故障：
                        故障产生是由于永久的问题导致的，并且这种问题不能通过额外的重试来解决。
                        比如常见的原因有软件bug或者无效的消息格式（例如，损坏（poison）的消息）            
                
    6. 伸缩
    
    7. 消费者复杂度
                    
            
            
            
            
            